{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-21T11:21:28.233959Z",
     "iopub.status.busy": "2024-08-21T11:21:28.233447Z",
     "iopub.status.idle": "2024-08-21T11:21:37.304866Z",
     "shell.execute_reply": "2024-08-21T11:21:37.303261Z",
     "shell.execute_reply.started": "2024-08-21T11:21:28.233921Z"
    },
    "id": "_e4BiYUZlYu0",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-21T11:21:37.308435Z",
     "iopub.status.busy": "2024-08-21T11:21:37.307504Z",
     "iopub.status.idle": "2024-08-21T11:21:37.315631Z",
     "shell.execute_reply": "2024-08-21T11:21:37.314101Z",
     "shell.execute_reply.started": "2024-08-21T11:21:37.308386Z"
    },
    "id": "KbLpuMMflDwo",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset_path = \"ISIC_2019_Training_Input\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 586
    },
    "execution": {
     "iopub.execute_input": "2024-08-21T11:21:37.317882Z",
     "iopub.status.busy": "2024-08-21T11:21:37.317379Z",
     "iopub.status.idle": "2024-08-21T11:21:37.811450Z",
     "shell.execute_reply": "2024-08-21T11:21:37.809935Z",
     "shell.execute_reply.started": "2024-08-21T11:21:37.317838Z"
    },
    "id": "Furw0cK2eV61",
    "outputId": "51ecb76b-972e-4401-a5dc-2e62ee7ceaaa",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "csv_path = \"ISIC_2019_Training_GroundTruth.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Sum the counts of each class\n",
    "class_counts = df.iloc[:, 1:].sum()\n",
    "\n",
    "# Plot the class distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(class_counts.index, class_counts.values, color='skyblue')\n",
    "\n",
    "# Add numbers on top of each bar\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.5, int(yval), ha='center', va='bottom')\n",
    "\n",
    "plt.title('Class Distribution in the Dataset')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Number of Data Points')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-21T11:21:37.814024Z",
     "iopub.status.busy": "2024-08-21T11:21:37.813514Z",
     "iopub.status.idle": "2024-08-21T11:21:37.831155Z",
     "shell.execute_reply": "2024-08-21T11:21:37.829744Z",
     "shell.execute_reply.started": "2024-08-21T11:21:37.813977Z"
    },
    "id": "WuRJL7mDoI_O",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_and_relabel_metadata(csv_path, output_path=None):\n",
    "    # Load the original metadata\n",
    "    df = pd.read_csv(csv_path)\n",
    "    # Define melanoma and non-melanoma categories\n",
    "    melanoma = ['MEL']\n",
    "    non_melanoma = ['NV', 'AK', 'BKL', 'DF', 'VASC', 'BCC', 'SCC']\n",
    "    # Drop the 'UNK' column (if present)\n",
    "    if 'UNK' in df.columns:\n",
    "        df = df.drop(['UNK'], axis=1)\n",
    "    # Create a new column 'class' where 1 represents melanoma and -1 represents non-melanoma\n",
    "    df['class'] = 2 * (df[melanoma].sum(axis=1) > 0).astype(int) - 1\n",
    "    # Drop the original class columns\n",
    "    df = df.drop(melanoma + non_melanoma, axis=1)\n",
    "    # Save the relabeled metadata to a new CSV file\n",
    "    if output_path is None:\n",
    "        output_path = \"relabeled_metadata_svm.csv\"\n",
    "    \n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"Relabeled metadata saved to: {output_path}\")\n",
    "    # Print statistics about the dataset\n",
    "    total_entries = len(df)\n",
    "    print(f\"\\nTotal entries in relabeled file: {total_entries}\")\n",
    "    return df\n",
    "\n",
    "def plot_class_distribution(relabeled_metadata):\n",
    "    # Get class counts\n",
    "    class_counts = relabeled_metadata['class'].value_counts().sort_index()\n",
    "    # Define custom colors for the bars\n",
    "    colors = ['#ff7f0e', '#1f77b4']  # Orange for non-melanoma (-1), blue for melanoma (1)\n",
    "    # Create a bar plot with colors and display actual counts\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    bars = plt.bar(['Non-Melanoma (-1)', 'Melanoma (1)'], class_counts.values, color=colors)\n",
    "    # Add text labels above the bars showing the count\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, yval, int(yval), ha='center', va='bottom', fontsize=12)\n",
    "    # Add labels and title\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Class Distribution for SVM')\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-21T11:21:37.834926Z",
     "iopub.status.busy": "2024-08-21T11:21:37.834443Z",
     "iopub.status.idle": "2024-08-21T11:21:38.426777Z",
     "shell.execute_reply": "2024-08-21T11:21:38.425324Z",
     "shell.execute_reply.started": "2024-08-21T11:21:37.834883Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load and relabel the metadata\n",
    "relabeled_df = load_and_relabel_metadata(csv_path)\n",
    "\n",
    "# Plot the class distribution\n",
    "plot_class_distribution(relabeled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-08-21T11:21:38.799814Z",
     "iopub.status.busy": "2024-08-21T11:21:38.799308Z",
     "iopub.status.idle": "2024-08-21T11:21:38.814013Z",
     "shell.execute_reply": "2024-08-21T11:21:38.812701Z",
     "shell.execute_reply.started": "2024-08-21T11:21:38.799768Z"
    },
    "id": "PtL3uaz0rw-c",
    "outputId": "5405f557-2c06-48da-a4a3-55baa0fdc72a",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Print the first few rows to verify the relabeling\n",
    "print(relabeled_df.head())\n",
    "\n",
    "# Print column names to verify\n",
    "print(\"\\nColumns in relabeled metadata:\")\n",
    "print(sum(relabeled_df['class'] == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split your dataset into train and test sets\n",
    "train_metadata_df, test_metadata_df = train_test_split(relabeled_df, test_size=0.2, stratify=relabeled_df['class'], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the class distribution\n",
    "plot_class_distribution(train_metadata_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the class distribution\n",
    "plot_class_distribution(test_metadata_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-21T11:21:38.816503Z",
     "iopub.status.busy": "2024-08-21T11:21:38.816020Z",
     "iopub.status.idle": "2024-08-21T11:21:38.873544Z",
     "shell.execute_reply": "2024-08-21T11:21:38.872173Z",
     "shell.execute_reply.started": "2024-08-21T11:21:38.816460Z"
    },
    "id": "V4HFfQJMYj5v",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def apply_augmentations(image):\n",
    "    \"\"\"Apply data augmentation to an input image before any other preprocessing.\"\"\"\n",
    "    augmented_images = []\n",
    "    augmented_names = []\n",
    "\n",
    "    # Base image\n",
    "    augmented_images.append(image)\n",
    "    augmented_names.append('original')\n",
    "\n",
    "    # 90 degree clockwise rotation\n",
    "    rotated_90 = cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE)\n",
    "    augmented_images.append(rotated_90)\n",
    "    augmented_names.append('rotated_90')\n",
    "\n",
    "    # 90 degree counterclockwise rotation\n",
    "    rotated_270 = cv2.rotate(image, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "    augmented_images.append(rotated_270)\n",
    "    augmented_names.append('rotated_270')\n",
    "\n",
    "    # Vertical flip\n",
    "    flipped = cv2.flip(image, 0)\n",
    "    augmented_images.append(flipped)\n",
    "    augmented_names.append('vertical_flip')\n",
    "\n",
    "    # Mirroring (horizontal flip)\n",
    "    mirrored = cv2.flip(image, 1)\n",
    "    augmented_images.append(mirrored)\n",
    "    augmented_names.append('mirrored')\n",
    "\n",
    "    return augmented_images, augmented_names\n",
    "\n",
    "def extract_roi(img_rgb):\n",
    "    \"\"\"Extract ROI from an RGB image.\"\"\"\n",
    "    gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)\n",
    "    \n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "    \n",
    "    mask = np.zeros(gray.shape, np.uint8)\n",
    "    cv2.drawContours(mask, [largest_contour], 0, 255, -1)\n",
    "    \n",
    "    roi = cv2.bitwise_and(img_rgb, img_rgb, mask=mask)\n",
    "    x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "    roi_cropped = roi[y:y+h, x:x+w]\n",
    "    \n",
    "    return roi_cropped\n",
    "\n",
    "def resize_and_pad(image, target_size=224):\n",
    "    \"\"\"Resize and pad image to target size.\"\"\"\n",
    "    old_size = image.shape[:2]\n",
    "    ratio = float(target_size) / max(old_size)\n",
    "    new_size = tuple([int(x * ratio) for x in old_size])\n",
    "    \n",
    "    resized = cv2.resize(image, (new_size[1], new_size[0]))\n",
    "    \n",
    "    delta_w = target_size - new_size[1]\n",
    "    delta_h = target_size - new_size[0]\n",
    "    top, bottom = delta_h // 2, delta_h - (delta_h // 2)\n",
    "    left, right = delta_w // 2, delta_w - (delta_w // 2)\n",
    "    \n",
    "    padded = cv2.copyMakeBorder(resized, top, bottom, left, right, cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
    "    return padded\n",
    "\n",
    "def process_single_image(image_path, apply_augmentation=True):\n",
    "    \"\"\"Process a single image with optional augmentation.\"\"\"\n",
    "    # Load and convert image\n",
    "    img = cv2.imread(image_path)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    processed_images = []\n",
    "    image_names = []\n",
    "    \n",
    "    if apply_augmentation:\n",
    "        # Apply augmentations first\n",
    "        augmented_images, aug_names = apply_augmentations(img_rgb)\n",
    "    else:\n",
    "        augmented_images = [img_rgb]\n",
    "        aug_names = ['original']\n",
    "    \n",
    "    # Process each augmented version\n",
    "    for aug_img, aug_name in zip(augmented_images, aug_names):\n",
    "        # Extract ROI\n",
    "        roi = extract_roi(aug_img)\n",
    "        \n",
    "        # Resize and pad\n",
    "        processed = resize_and_pad(roi)\n",
    "        \n",
    "        # Preprocess for model\n",
    "        processed = preprocess_input(processed.astype(np.float32))\n",
    "        \n",
    "        processed_images.append(processed)\n",
    "        image_names.append(aug_name)\n",
    "    \n",
    "    return processed_images, image_names\n",
    "\n",
    "def process_dataset_with_metadata(metadata_df, dataset_path, output_dir, apply_augmentation=True, is_training=True):\n",
    "    \"\"\"Process entire dataset with metadata.\n",
    "    \n",
    "    Processes all images in the dataset, ensuring:\n",
    "    1. All non-melanoma images are saved\n",
    "    2. All original melanoma images are processed first\n",
    "    3. Augmentations are only applied to melanoma images if needed to balance the dataset\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    all_class_encodings = []\n",
    "    all_image_names = []\n",
    "    \n",
    "    # Calculate dataset statistics\n",
    "    non_melanoma_count = sum(metadata_df['class'] == -1)\n",
    "    melanoma_count = sum(metadata_df['class'] == 1)\n",
    "    \n",
    "    # Calculate how many additional melanoma samples we need\n",
    "    if is_training and apply_augmentation:\n",
    "        target_melanoma_count = non_melanoma_count\n",
    "        melanoma_images_needed = target_melanoma_count - melanoma_count\n",
    "    else:\n",
    "        melanoma_images_needed = 0\n",
    "    \n",
    "    total_images = len(metadata_df)  # Changed from metadata_df['image']\n",
    "    \n",
    "    # First pass: Process all original images (both melanoma and non-melanoma)\n",
    "    print(\"Processing all original images...\")\n",
    "    for index, row in metadata_df.iterrows():  # Changed to iterate over rows\n",
    "        image_name = row['image']\n",
    "        class_encoding = row['class']  # Get class directly from row\n",
    "        \n",
    "        print(f\"Processing original image {index + 1}/{total_images}: {image_name}\")\n",
    "        \n",
    "        image_path = os.path.join(dataset_path, image_name + '.jpg')\n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"Error: Image file not found at {image_path}\")\n",
    "            continue\n",
    "        \n",
    "        # Process original image without augmentation\n",
    "        processed_images, image_names = process_single_image(image_path, apply_augmentation=False)\n",
    "        \n",
    "        # Save processed original image\n",
    "        base_name = os.path.splitext(image_name)[0]\n",
    "        for proc_img, img_name in zip(processed_images, image_names):\n",
    "            save_path = os.path.join(output_dir, f\"{base_name}_{img_name}.npy\")\n",
    "            np.save(save_path, proc_img)\n",
    "            all_image_names.append(f\"{base_name}_{img_name}.npy\")\n",
    "            all_class_encodings.append(class_encoding)  # Use class from metadata\n",
    "    \n",
    "    # Second pass: Apply augmentations to melanoma images if needed\n",
    "    if is_training and apply_augmentation and melanoma_images_needed > 0:\n",
    "        print(\"\\nApplying augmentations to melanoma images...\")\n",
    "        melanoma_images = metadata_df[metadata_df['class'] == 1]  # Changed to get full rows\n",
    "        \n",
    "        additional_melanoma_count = 0\n",
    "        for _, row in melanoma_images.iterrows():  # Changed to iterate over rows\n",
    "            if additional_melanoma_count >= melanoma_images_needed:\n",
    "                break\n",
    "                \n",
    "            image_name = row['image']\n",
    "            image_path = os.path.join(dataset_path, image_name + '.jpg')\n",
    "            if not os.path.exists(image_path):\n",
    "                continue\n",
    "            \n",
    "            # Process image with augmentation\n",
    "            processed_images, image_names = process_single_image(image_path, apply_augmentation=True)\n",
    "            \n",
    "            # Save augmented versions (skip the first one as it's the original)\n",
    "            base_name = os.path.splitext(image_name)[0]\n",
    "            for proc_img, img_name in zip(processed_images[1:], image_names[1:]):  # Skip original\n",
    "                if additional_melanoma_count >= melanoma_images_needed:\n",
    "                    break\n",
    "                    \n",
    "                save_path = os.path.join(output_dir, f\"{base_name}_{img_name}.npy\")\n",
    "                np.save(save_path, proc_img)\n",
    "                all_image_names.append(f\"{base_name}_{img_name}.npy\")\n",
    "                all_class_encodings.append(1)  # class encoding for melanoma\n",
    "                additional_melanoma_count += 1\n",
    "    \n",
    "    print(\"\\nProcessing complete.\")\n",
    "    if is_training and apply_augmentation:\n",
    "        final_melanoma_count = melanoma_count + additional_melanoma_count\n",
    "        print(f\"Original melanoma images: {melanoma_count}\")\n",
    "        print(f\"Additional augmented melanoma images: {additional_melanoma_count}\")\n",
    "        print(f\"Final melanoma count: {final_melanoma_count}\")\n",
    "        print(f\"Non-melanoma count: {non_melanoma_count}\")\n",
    "        print(f\"Total images processed: {len(all_class_encodings)}\")\n",
    "        print(f\"Difference: {final_melanoma_count - non_melanoma_count}\")\n",
    "\n",
    "    return all_class_encodings, all_image_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_output_dir = 'preprocessed/train'\n",
    "test_output_dir = 'preprocessed/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-08-21T11:21:38.892968Z",
     "iopub.status.busy": "2024-08-21T11:21:38.892555Z",
     "iopub.status.idle": "2024-08-21T11:49:27.206721Z",
     "shell.execute_reply": "2024-08-21T11:49:27.205366Z",
     "shell.execute_reply.started": "2024-08-21T11:21:38.892933Z"
    },
    "id": "lBhIjZTGU65k",
    "outputId": "c9192f58-15f1-40e8-fbaa-fd6c2ead649c",
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Process training set with augmentation for balance\n",
    "train_encodings, train_images = process_dataset_with_metadata(\n",
    "    metadata_df=train_metadata_df,\n",
    "    dataset_path='ISIC_2019_Training_Input',\n",
    "    output_dir=train_output_dir,\n",
    "    apply_augmentation=True,\n",
    "    is_training=True  # This ensures augmentation is applied only to training set\n",
    ")\n",
    "\n",
    "# Process test/validation set without augmentation\n",
    "test_encodings, test_images = process_dataset_with_metadata(\n",
    "    metadata_df=test_metadata_df,\n",
    "    dataset_path='ISIC_2019_Training_Input',\n",
    "    output_dir=test_output_dir,\n",
    "    apply_augmentation=False,  # No augmentation for test set\n",
    "    is_training=False  # Indicates this is test/validation data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv(class_encodings, image_names, output_dir, prefix):\n",
    "    \"\"\"Save image names and class encodings to CSV file with validation.\"\"\"\n",
    "    # Create the directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Create a DataFrame with image names and their corresponding class encodings\n",
    "    df = pd.DataFrame({\n",
    "        'image_name': image_names,\n",
    "        'class': class_encodings\n",
    "    })\n",
    "    \n",
    "    # Validate the data\n",
    "    melanoma_count = sum(df['class'] == 1)\n",
    "    non_melanoma_count = sum(df['class'] == -1)\n",
    "    total_count = len(df)\n",
    "    \n",
    "    print(\"\\nDataset Statistics:\")\n",
    "    print(f\"Total images: {total_count}\")\n",
    "    print(f\"Melanoma images: {melanoma_count}\")\n",
    "    print(f\"Non-melanoma images: {non_melanoma_count}\")\n",
    "    print(f\"Class distribution: {df['class'].value_counts()}\")\n",
    "    \n",
    "    # Save the DataFrame to a CSV file\n",
    "    csv_path = os.path.join(output_dir, f\"{prefix}_ground_truth.csv\")\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"\\nGround truth saved to: {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_output_dir = \"preprocessed/train/ground_truth\"\n",
    "test_output_dir = \"preprocessed/test/ground_truth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_csv(\n",
    "    class_encodings=train_encodings,\n",
    "    image_names=train_images,\n",
    "    output_dir=train_output_dir,\n",
    "    prefix=\"train\"\n",
    ")\n",
    "\n",
    "save_to_csv(\n",
    "    class_encodings=test_encodings,\n",
    "    image_names=test_images,\n",
    "    output_dir=test_output_dir,\n",
    "    prefix=\"test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('preprocessed/train/ground_truth/train_ground_truth.csv')\n",
    "\n",
    "# Assuming your dataframe has a column named 'class' for the class labels\n",
    "# Count the occurrences of each class\n",
    "class_counts = data['class'].value_counts()\n",
    "\n",
    "# Create a histogram\n",
    "plt.figure(figsize=(5, 5))\n",
    "bars = plt.bar(class_counts.index, class_counts.values, color=['blue', 'orange'], alpha=0.7)\n",
    "\n",
    "# Set the title and labels\n",
    "plt.title('Class Distribution: Melanoma vs Non-Melanoma', fontsize=14)\n",
    "plt.xlabel('Classes', fontsize=12)\n",
    "plt.ylabel('Number of Samples', fontsize=12)\n",
    "plt.xticks(ticks=[-1, 1], labels=['Non-Melanoma (-1)', 'Melanoma (1)'])\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add exact counts on top of the bars\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval, int(yval), ha='center', va='bottom', fontsize=12)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction with MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-08-21T11:56:38.654058Z",
     "iopub.status.busy": "2024-08-21T11:56:38.653486Z"
    },
    "id": "YPeKDbx8UU9k",
    "outputId": "648a077c-9920-45d0-fcc9-3f1353420bc1",
    "scrolled": true,
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (33294, 1280)\n",
      "Training labels shape: (33294,)\n",
      "Test features shape: (5067, 1280)\n",
      "Test labels shape: (5067,)\n"
     ]
    }
   ],
   "source": [
    "def setup_model():\n",
    "    input_shape = (224, 224, 3)\n",
    "    base_model = MobileNetV2(input_shape=input_shape, weights='imagenet', include_top=False, pooling='avg')\n",
    "    base_model.trainable = False  # Freeze the base model\n",
    "    return base_model\n",
    "\n",
    "def get_features(image_path, features_dir, base_model):\n",
    "    base_filename = os.path.splitext(os.path.basename(image_path))[0]\n",
    "    features_path = os.path.join(features_dir, base_filename + '.npy')\n",
    "    \n",
    "    if os.path.exists(features_path):\n",
    "        features = np.load(features_path)\n",
    "    else:\n",
    "        img_array = np.load(image_path)\n",
    "        \n",
    "        if img_array.shape != (224, 224, 3):\n",
    "            raise ValueError(f\"Loaded image shape {img_array.shape} does not match expected input shape (224, 224, 3)\")\n",
    "\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        features = base_model.predict(img_array).flatten()\n",
    "        np.save(features_path, features)\n",
    "    \n",
    "    return features\n",
    "\n",
    "def extract_features(df, preprocessed_dir, features_dir, base_model):\n",
    "    os.makedirs(features_dir, exist_ok=True)\n",
    "\n",
    "    features = []\n",
    "    for _, row in df.iterrows():\n",
    "        image_path = os.path.join(preprocessed_dir, row['image_name'])\n",
    "        features.append(get_features(image_path, features_dir, base_model))\n",
    "\n",
    "    return np.array(features)\n",
    "\n",
    "def process_dataset(ground_truth_path, preprocessed_dir, features_dir, base_model):\n",
    "    df = pd.read_csv(ground_truth_path)\n",
    "    features = extract_features(df, preprocessed_dir, features_dir, base_model)\n",
    "    return features, df['class'].values\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    base_model = setup_model()\n",
    "\n",
    "    # Paths for training set\n",
    "    train_ground_truth_path = os.path.join(train_output_dir, \"ground_truth\",\"train_ground_truth.csv\")\n",
    "    train_features_dir = 'preprocessed/train/extracted_features_gpu'  # Updated to save directly in preprocessed/train\n",
    "    preprocessed_train_dir = 'preprocessed/train'\n",
    "\n",
    "    # Process training set\n",
    "    X_train, y_train = process_dataset(train_ground_truth_path, preprocessed_train_dir, train_features_dir, base_model)\n",
    "    print(f\"Training features shape: {X_train.shape}\")\n",
    "    print(f\"Training labels shape: {y_train.shape}\")\n",
    "\n",
    "    # Paths for test set\n",
    "    test_ground_truth_path = os.path.join(test_output_dir, \"ground_truth\", \"test_ground_truth.csv\")\n",
    "    test_features_dir = 'preprocessed/test/extracted_features_gpu'  # Updated to save directly in preprocessed/test\n",
    "    preprocessed_test_dir = 'preprocessed/test'\n",
    "\n",
    "    # Process test set\n",
    "    X_test, y_test = process_dataset(test_ground_truth_path, preprocessed_test_dir, test_features_dir, base_model)\n",
    "    print(f\"Test features shape: {X_test.shape}\")\n",
    "    print(f\"Test labels shape: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, recall_score\n",
    "from cvxopt import matrix, spmatrix, solvers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM:\n",
    "    def __init__(self, C=1.0):\n",
    "        self.C = C\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        K = np.dot(X, X.T)\n",
    "\n",
    "        P = matrix(np.outer(y, y) * K)\n",
    "        q = matrix(-1 * np.ones(n_samples))\n",
    "        A = matrix(y, (1, n_samples), 'd')\n",
    "        b = matrix(0.0)\n",
    "\n",
    "        G = spmatrix([], [], [], (n_samples * 2, n_samples))\n",
    "        G[:n_samples, :n_samples] = spmatrix(-1.0, range(n_samples), range(n_samples))  # -alpha <= 0 (for soft margin)\n",
    "        G[n_samples:, :n_samples] = spmatrix(1.0, range(n_samples), range(n_samples))   # alpha <= C\n",
    "\n",
    "        h = matrix(np.hstack((np.zeros(n_samples), np.ones(n_samples) * self.C)))\n",
    "\n",
    "        # Solve QP problem\n",
    "        solution = solvers.qp(P, q, G, h, A, b)\n",
    "\n",
    "        # Lagrange multipliers\n",
    "        a = np.ravel(solution['x'])\n",
    "\n",
    "        # Support vectors have non-zero Lagrange multipliers\n",
    "        sv = a > 1e-5\n",
    "        ind = np.arange(len(a))[sv]\n",
    "        self.a = a[sv]\n",
    "        self.sv = X[sv]\n",
    "        self.sv_y = y[sv]\n",
    "\n",
    "        # Intercept\n",
    "        self.b = 0\n",
    "        for n in range(len(self.a)):\n",
    "            self.b += self.sv_y[n]\n",
    "            self.b -= np.sum(self.a * self.sv_y * K[ind[n], sv])\n",
    "        self.b /= len(self.a)\n",
    "\n",
    "        # Weight vector\n",
    "        self.w = np.zeros(n_features)\n",
    "        for n in range(len(self.a)):\n",
    "            self.w += self.a[n] * self.sv_y[n] * self.sv[n]\n",
    "\n",
    "    def project(self, X):\n",
    "        return np.dot(X, self.w) + self.b\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.sign(self.project(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing model with C = 0.001\n",
      "Model already exists for C = 0.001. Skipping training.\n",
      "Processing model with C = 0.01\n",
      "Model already exists for C = 0.01. Skipping training.\n",
      "Processing model with C = 0.1\n",
      "Model already exists for C = 0.1. Skipping training.\n",
      "Processing model with C = 0.2\n",
      "Model already exists for C = 0.2. Skipping training.\n",
      "Processing model with C = 0.3\n",
      "Model already exists for C = 0.3. Skipping training.\n",
      "Processing model with C = 0.4\n",
      "Model already exists for C = 0.4. Skipping training.\n",
      "Processing model with C = 0.5\n",
      "Model already exists for C = 0.5. Skipping training.\n",
      "Processing model with C = 1\n",
      "Model already exists for C = 1. Skipping training.\n",
      "Processing model with C = 10\n",
      "Training model with C = 10\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.1692e+05 -4.1598e+06  1e+07  1e+00  8e-08\n",
      " 1: -1.1024e+05 -2.3222e+06  3e+06  2e-01  9e-08\n",
      " 2: -1.1046e+05 -8.1907e+05  8e+05  4e-02  9e-08\n",
      " 3: -1.2326e+05 -3.0181e+05  2e+05  9e-03  1e-07\n",
      " 4: -1.4018e+05 -2.5699e+05  1e+05  5e-03  1e-07\n",
      " 5: -1.5185e+05 -2.2579e+05  8e+04  3e-03  1e-07\n",
      " 6: -1.5801e+05 -2.1087e+05  5e+04  2e-03  1e-07\n",
      " 7: -1.6370e+05 -1.9748e+05  3e+04  9e-04  1e-07\n",
      " 8: -1.6676e+05 -1.9075e+05  2e+04  6e-04  1e-07\n",
      " 9: -1.6905e+05 -1.8591e+05  2e+04  4e-04  1e-07\n",
      "10: -1.7068e+05 -1.8259e+05  1e+04  2e-04  1e-07\n",
      "11: -1.7203e+05 -1.7991e+05  8e+03  1e-04  1e-07\n",
      "12: -1.7253e+05 -1.7892e+05  6e+03  9e-05  1e-07\n",
      "13: -1.7327e+05 -1.7755e+05  4e+03  5e-05  1e-07\n",
      "14: -1.7369e+05 -1.7678e+05  3e+03  3e-05  1e-07\n",
      "15: -1.7393e+05 -1.7640e+05  2e+03  2e-05  1e-07\n",
      "16: -1.7399e+05 -1.7628e+05  2e+03  2e-05  1e-07\n",
      "17: -1.7399e+05 -1.7627e+05  2e+03  1e-05  1e-07\n",
      "18: -1.7422e+05 -1.7594e+05  2e+03  1e-05  1e-07\n",
      "19: -1.7436e+05 -1.7572e+05  1e+03  6e-06  1e-07\n",
      "20: -1.7448e+05 -1.7557e+05  1e+03  4e-06  1e-07\n",
      "21: -1.7448e+05 -1.7556e+05  1e+03  4e-06  1e-07\n",
      "Terminated (singular KKT matrix).\n",
      "Model trained and saved to: models_linear\\svm_model_C_10.joblib\n",
      "All models processed.\n"
     ]
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "import gc\n",
    "\n",
    "# Test with multiple values of C\n",
    "C_values = [0.001, 0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 1, 10]\n",
    "\n",
    "# Ensure the models directory exists\n",
    "os.makedirs('models_linear', exist_ok=True)\n",
    "\n",
    "for C in C_values:\n",
    "    print(f\"Processing model with C = {C}\")\n",
    "    \n",
    "    # Define the model file path\n",
    "    model_path = os.path.join('models_linear', f'svm_model_C_{C}.joblib')\n",
    "\n",
    "    # Check if the model already exists\n",
    "    if os.path.exists(model_path):\n",
    "        print(f\"Model already exists for C = {C}. Skipping training.\")\n",
    "    else:\n",
    "        print(f\"Training model with C = {C}\")\n",
    "        model = SVM(C=C)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Save the model\n",
    "        dump(model, model_path, compress=3)\n",
    "        print(f\"Model trained and saved to: {model_path}\")\n",
    "\n",
    "        # Clear the model from memory\n",
    "        del model\n",
    "        gc.collect()  # Force garbage collection\n",
    "\n",
    "print(\"All models processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing models:\n",
      "\n",
      "Testing model with C = 0.001\n",
      "X_test.shape: (5067, 1280)\n",
      "y_test.shape: (5067,)\n",
      "Projected: [-0.60761615 -0.3856599  -0.36152271 -1.994356   -1.38427855]\n",
      "Predicted: [-1. -1. -1. -1. -1.]\n",
      "Confusion Matrix:\n",
      " [[3145 1017]\n",
      " [ 254  651]]\n",
      "Recall for C = 0.001: 0.7193\n",
      "\n",
      "Testing model with C = 0.01\n",
      "X_test.shape: (5067, 1280)\n",
      "y_test.shape: (5067,)\n",
      "Projected: [-0.45812577 -0.08704579 -0.70860055 -2.21099101 -2.41202388]\n",
      "Predicted: [-1. -1. -1. -1. -1.]\n",
      "Confusion Matrix:\n",
      " [[3160 1002]\n",
      " [ 260  645]]\n",
      "Recall for C = 0.01: 0.7127\n",
      "\n",
      "Testing model with C = 0.1\n",
      "X_test.shape: (5067, 1280)\n",
      "y_test.shape: (5067,)\n",
      "Projected: [-0.26661497  0.29994617 -0.89112706 -2.40551467 -3.02374501]\n",
      "Predicted: [-1.  1. -1. -1. -1.]\n",
      "Confusion Matrix:\n",
      " [[3148 1014]\n",
      " [ 258  647]]\n",
      "Recall for C = 0.1: 0.7149\n",
      "\n",
      "Testing model with C = 0.2\n",
      "X_test.shape: (5067, 1280)\n",
      "y_test.shape: (5067,)\n",
      "Projected: [-0.27643086  0.34721812 -0.92652649 -2.38582313 -3.06615463]\n",
      "Predicted: [-1.  1. -1. -1. -1.]\n",
      "Confusion Matrix:\n",
      " [[3157 1005]\n",
      " [ 258  647]]\n",
      "Recall for C = 0.2: 0.7149\n",
      "\n",
      "Testing model with C = 0.3\n",
      "X_test.shape: (5067, 1280)\n",
      "y_test.shape: (5067,)\n",
      "Projected: [-0.24720034  0.31968704 -0.95827075 -2.38619655 -3.05178076]\n",
      "Predicted: [-1.  1. -1. -1. -1.]\n",
      "Confusion Matrix:\n",
      " [[3154 1008]\n",
      " [ 259  646]]\n",
      "Recall for C = 0.3: 0.7138\n",
      "\n",
      "Testing model with C = 0.4\n",
      "X_test.shape: (5067, 1280)\n",
      "y_test.shape: (5067,)\n",
      "Projected: [-0.2830311   0.33897585 -0.99108544 -2.44441461 -3.07783513]\n",
      "Predicted: [-1.  1. -1. -1. -1.]\n",
      "Confusion Matrix:\n",
      " [[3153 1009]\n",
      " [ 260  645]]\n",
      "Recall for C = 0.4: 0.7127\n",
      "\n",
      "Testing model with C = 0.5\n",
      "X_test.shape: (5067, 1280)\n",
      "y_test.shape: (5067,)\n",
      "Projected: [-0.29825068  0.34273339 -1.02550692 -2.47169134 -3.09178564]\n",
      "Predicted: [-1.  1. -1. -1. -1.]\n",
      "Confusion Matrix:\n",
      " [[3152 1010]\n",
      " [ 261  644]]\n",
      "Recall for C = 0.5: 0.7116\n",
      "\n",
      "Testing model with C = 1\n",
      "X_test.shape: (5067, 1280)\n",
      "y_test.shape: (5067,)\n",
      "Projected: [ 0.32774445  0.0640603  -0.5849552  -1.27359773 -2.55107406]\n",
      "Predicted: [ 1.  1. -1. -1. -1.]\n",
      "Confusion Matrix:\n",
      " [[3012 1150]\n",
      " [ 300  605]]\n",
      "Recall for C = 1: 0.6685\n",
      "\n",
      "Testing model with C = 10\n",
      "X_test.shape: (5067, 1280)\n",
      "y_test.shape: (5067,)\n",
      "Projected: [-0.3521308   0.32690762 -1.00444708 -2.72058938 -3.45476438]\n",
      "Predicted: [-1.  1. -1. -1. -1.]\n",
      "Confusion Matrix:\n",
      " [[3211  951]\n",
      " [ 267  638]]\n",
      "Recall for C = 10: 0.7050\n",
      "\n",
      "Testing completed.\n"
     ]
    }
   ],
   "source": [
    "# Testing phase\n",
    "print(\"\\nTesting models:\")\n",
    "for C in C_values:\n",
    "    print(f\"\\nTesting model with C = {C}\")\n",
    "    \n",
    "    model_path = os.path.join('models_linear', f'svm_model_C_{C}.joblib')\n",
    "    \n",
    "    # Load the model\n",
    "    model = load(model_path)\n",
    "    \n",
    "    # Perform predictions on the test set\n",
    "    print('X_test.shape:', X_test.shape)\n",
    "    print('y_test.shape:', y_test.shape)\n",
    "    y_proj = model.project(X_test)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Display first few results\n",
    "    print('Projected:', y_proj[:5])\n",
    "    print('Predicted:', y_pred[:5])\n",
    "    \n",
    "    # Confusion matrix and recall\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    \n",
    "    print('Confusion Matrix:\\n', cm)\n",
    "    print(f'Recall for C = {C}: {recall:.4f}')\n",
    "\n",
    "    # Clear the model from memory\n",
    "    del model\n",
    "    gc.collect()\n",
    "\n",
    "print(\"\\nTesting completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from cvxopt import matrix, solvers\n",
    "from cvxopt import spmatrix\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import numba\n",
    "\n",
    "class SVM_RBF:\n",
    "    def __init__(self, C=1.0, gamma=0.1, chunk_size=1000, tolerance=1e-5):\n",
    "        self.C = C\n",
    "        self.gamma = gamma\n",
    "        self.chunk_size = chunk_size\n",
    "        self.tolerance = tolerance\n",
    "\n",
    "    @staticmethod\n",
    "    @numba.jit(nopython=True, parallel=True)\n",
    "    def _rbf_kernel_numba(X1, X2, gamma):\n",
    "        \"\"\"\n",
    "        Accelerated RBF kernel computation using Numba\n",
    "        \"\"\"\n",
    "        n_samples1, n_features = X1.shape\n",
    "        n_samples2 = X2.shape[0]\n",
    "        K = np.zeros((n_samples1, n_samples2))\n",
    "        \n",
    "        for i in numba.prange(n_samples1):\n",
    "            for j in range(n_samples2):\n",
    "                dist = 0.0\n",
    "                for k in range(n_features):\n",
    "                    diff = X1[i, k] - X2[j, k]\n",
    "                    dist += diff * diff\n",
    "                K[i, j] = np.exp(-gamma * dist)\n",
    "        return K\n",
    "\n",
    "    def rbf_kernel_chunk(self, X1, X2, start, end):\n",
    "        \"\"\"\n",
    "        Optimized RBF kernel computation using broadcasting and Numba\n",
    "        \"\"\"\n",
    "        return self._rbf_kernel_numba(X1[start:end], X2, self.gamma)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples = X.shape[0]\n",
    "        \n",
    "        # Pre-compute kernel matrix more efficiently using chunks\n",
    "        P = np.zeros((n_samples, n_samples))\n",
    "        for i in range(0, n_samples, self.chunk_size):\n",
    "            end_i = min(i + self.chunk_size, n_samples)\n",
    "            K_chunk = self.rbf_kernel_chunk(X, X, i, end_i)\n",
    "            P[i:end_i] = K_chunk\n",
    "            \n",
    "        # Make kernel matrix symmetric\n",
    "        P = (P + P.T) / 2\n",
    "        \n",
    "        # Construct QP problem with sparse matrices where possible\n",
    "        P = matrix(np.outer(y, y) * P)\n",
    "        q = matrix(-1.0 * np.ones(n_samples))\n",
    "        A = matrix(y.astype(float), (1, n_samples))\n",
    "        b = matrix(0.0)\n",
    "        \n",
    "        # Use sparse matrix for constraints\n",
    "        G_sparse = spmatrix(\n",
    "            [-1.0] * n_samples + [1.0] * n_samples,\n",
    "            list(range(2 * n_samples)),\n",
    "            list(range(n_samples)) * 2\n",
    "        )\n",
    "        h = matrix(np.hstack((np.zeros(n_samples), np.ones(n_samples) * self.C)))\n",
    "\n",
    "        # Solve QP problem with optimized settings\n",
    "        solvers.options['show_progress'] = True\n",
    "        solution = solvers.qp(P, q, G_sparse, h, A, b)\n",
    "\n",
    "        # Extract support vectors more efficiently\n",
    "        a = np.ravel(solution['x'])\n",
    "        sv_mask = a > self.tolerance\n",
    "        self.a = a[sv_mask]\n",
    "        self.sv = X[sv_mask]\n",
    "        self.sv_y = y[sv_mask]\n",
    "        \n",
    "        # Vectorized intercept calculation\n",
    "        K_sv = self._rbf_kernel_numba(self.sv, self.sv, self.gamma)\n",
    "        self.b = np.mean(\n",
    "            self.sv_y - np.sum(self.a * self.sv_y * K_sv, axis=1)\n",
    "        )\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Vectorized prediction with chunking for memory efficiency\n",
    "        \"\"\"\n",
    "        predictions = np.zeros(X.shape[0])\n",
    "        for i in range(0, X.shape[0], self.chunk_size):\n",
    "            end = min(i + self.chunk_size, X.shape[0])\n",
    "            K = self._rbf_kernel_numba(X[i:end], self.sv, self.gamma)\n",
    "            predictions[i:end] = np.dot(K, self.a * self.sv_y) + self.b\n",
    "        return np.sign(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing model with C = 0.001 and gamma = 0.0001\n",
      "Training model with C = 0.001 and gamma = 0.0001\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.1960e+04 -3.9717e+02  3e+05  6e+02  2e-11\n",
      " 1: -8.3514e+02 -1.8275e+02  2e+04  3e+01  1e-11\n",
      " 2: -1.0467e+02 -9.7637e+01  1e+03  2e+00  2e-12\n",
      " 3: -2.4708e+01 -8.6430e+01  6e+01  4e-13  2e-13\n",
      " 4: -2.8326e+01 -4.1177e+01  1e+01  2e-13  6e-14\n",
      " 5: -3.2625e+01 -3.3547e+01  9e-01  9e-14  6e-14\n",
      " 6: -3.3038e+01 -3.3047e+01  9e-03  8e-14  6e-14\n",
      " 7: -3.3042e+01 -3.3042e+01  9e-05  2e-13  6e-14\n",
      " 8: -3.3042e+01 -3.3042e+01  9e-07  2e-13  6e-14\n",
      "Optimal solution found.\n",
      "Model trained and saved to: models_rbf\\svm_rbf_model_C_0.001_gamma_0.0001.joblib\n",
      "Processing model with C = 0.001 and gamma = 0.001\n",
      "Training model with C = 0.001 and gamma = 0.001\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -9.6852e+03 -6.2516e+02  3e+05  5e+02  6e-12\n",
      " 1: -9.4216e+02 -1.6472e+02  2e+04  3e+01  6e-12\n",
      " 2: -1.0991e+02 -9.6375e+01  1e+03  2e+00  8e-13\n",
      " 3: -2.6119e+01 -8.3374e+01  8e+01  5e-02  9e-14\n",
      " 4: -2.7224e+01 -4.4349e+01  2e+01  1e-02  3e-14\n",
      " 5: -3.0838e+01 -3.3210e+01  2e+00  4e-04  3e-14\n",
      " 6: -3.1935e+01 -3.1987e+01  5e-02  7e-06  3e-14\n",
      " 7: -3.1964e+01 -3.1964e+01  5e-04  7e-08  3e-14\n",
      " 8: -3.1964e+01 -3.1964e+01  5e-06  7e-10  3e-14\n",
      "Optimal solution found.\n",
      "Model trained and saved to: models_rbf\\svm_rbf_model_C_0.001_gamma_0.001.joblib\n",
      "Processing model with C = 0.001 and gamma = 0.01\n",
      "Training model with C = 0.001 and gamma = 0.01\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -6.3499e+03 -1.6575e+03  2e+05  5e+02  6e-14\n",
      " 1: -1.6614e+03 -2.7267e+02  2e+04  4e+01  6e-14\n",
      " 2: -2.0995e+02 -8.9723e+01  2e+03  3e+00  2e-14\n",
      " 3: -2.7194e+01 -7.9383e+01  7e+01  4e-02  2e-14\n",
      " 4: -2.8750e+01 -4.2368e+01  2e+01  8e-03  1e-14\n",
      " 5: -3.2505e+01 -3.3718e+01  1e+00  2e-04  1e-14\n",
      " 6: -3.3127e+01 -3.3139e+01  1e-02  2e-06  1e-14\n",
      " 7: -3.3133e+01 -3.3133e+01  1e-04  2e-08  1e-14\n",
      " 8: -3.3133e+01 -3.3133e+01  1e-06  2e-10  1e-14\n",
      "Optimal solution found.\n",
      "Model trained and saved to: models_rbf\\svm_rbf_model_C_0.001_gamma_0.01.joblib\n",
      "Processing model with C = 0.001 and gamma = 0.1\n",
      "Training model with C = 0.001 and gamma = 0.1\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -9.2009e+03 -1.9208e+03  2e+05  4e+02  3e-15\n",
      " 1: -1.7136e+03 -1.1807e+02  1e+04  3e+01  3e-15\n",
      " 2: -5.0430e+01 -7.1209e+01  2e+02  5e-01  8e-15\n",
      " 3: -2.7725e+01 -5.5356e+01  3e+01  8e-13  3e-15\n",
      " 4: -3.1864e+01 -3.4326e+01  2e+00  6e-13  2e-15\n",
      " 5: -3.3262e+01 -3.3289e+01  3e-02  2e-12  2e-15\n",
      " 6: -3.3277e+01 -3.3277e+01  3e-04  1e-12  8e-16\n",
      " 7: -3.3277e+01 -3.3277e+01  3e-06  3e-13  5e-16\n",
      "Optimal solution found.\n",
      "Model trained and saved to: models_rbf\\svm_rbf_model_C_0.001_gamma_0.1.joblib\n",
      "Processing model with C = 0.001 and gamma = 1\n",
      "Training model with C = 0.001 and gamma = 1\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -9.2485e+03 -1.9149e+03  1e+05  4e+02  2e-16\n",
      " 1: -1.4867e+03 -1.0304e+02  7e+03  2e+01  9e-16\n",
      " 2: -3.8316e+01 -6.8888e+01  8e+01  1e-01  9e-16\n",
      " 3: -3.0646e+01 -4.0444e+01  1e+01  1e-12  2e-16\n",
      " 4: -3.3160e+01 -3.3349e+01  2e-01  3e-12  2e-16\n",
      " 5: -3.3276e+01 -3.3278e+01  2e-03  6e-12  4e-16\n",
      " 6: -3.3277e+01 -3.3277e+01  2e-05  3e-12  3e-16\n",
      "Optimal solution found.\n",
      "Model trained and saved to: models_rbf\\svm_rbf_model_C_0.001_gamma_1.joblib\n",
      "Processing model with C = 0.001 and gamma = 10\n",
      "Training model with C = 0.001 and gamma = 10\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -9.2486e+03 -1.9149e+03  1e+05  4e+02  2e-16\n",
      " 1: -1.4867e+03 -1.0304e+02  7e+03  2e+01  1e-15\n",
      " 2: -3.8315e+01 -6.8888e+01  8e+01  1e-01  3e-16\n",
      " 3: -3.0646e+01 -4.0443e+01  1e+01  5e-12  3e-17\n",
      " 4: -3.3160e+01 -3.3349e+01  2e-01  3e-12  2e-16\n",
      " 5: -3.3276e+01 -3.3278e+01  2e-03  3e-12  2e-16\n",
      " 6: -3.3277e+01 -3.3277e+01  2e-05  1e-11  4e-16\n",
      "Optimal solution found.\n",
      "Model trained and saved to: models_rbf\\svm_rbf_model_C_0.001_gamma_10.joblib\n",
      "Processing model with C = 0.01 and gamma = 0.0001\n",
      "Training model with C = 0.01 and gamma = 0.0001\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.2064e+04 -1.1899e+03  3e+05  3e+02  2e-11\n",
      " 1: -9.6550e+02 -9.8289e+02  2e+04  1e+01  1e-11\n",
      " 2: -2.5888e+02 -8.6637e+02  1e+03  4e-01  1e-12\n",
      " 3: -2.5983e+02 -4.1944e+02  2e+02  6e-02  5e-13\n",
      " 4: -2.9904e+02 -3.1733e+02  2e+01  3e-03  5e-13\n",
      " 5: -2.9943e+02 -3.1709e+02  2e+01  3e-03  5e-13\n",
      " 6: -3.0170e+02 -3.1477e+02  1e+01  2e-03  5e-13\n",
      " 7: -3.0314e+02 -3.1333e+02  1e+01  1e-03  4e-13\n",
      " 8: -3.0458e+02 -3.1183e+02  7e+00  7e-04  4e-13\n",
      " 9: -3.0570e+02 -3.1068e+02  5e+00  4e-04  4e-13\n",
      "10: -3.0661e+02 -3.0974e+02  3e+00  2e-04  4e-13\n",
      "11: -3.0709e+02 -3.0924e+02  2e+00  1e-04  4e-13\n",
      "12: -3.0751e+02 -3.0880e+02  1e+00  8e-05  4e-13\n",
      "13: -3.0774e+02 -3.0856e+02  8e-01  4e-05  5e-13\n",
      "14: -3.0793e+02 -3.0836e+02  4e-01  2e-05  5e-13\n",
      "15: -3.0804e+02 -3.0825e+02  2e-01  8e-06  5e-13\n",
      "16: -3.0809e+02 -3.0820e+02  1e-01  3e-06  5e-13\n",
      "17: -3.0812e+02 -3.0816e+02  3e-02  7e-07  5e-13\n",
      "18: -3.0814e+02 -3.0814e+02  8e-03  1e-07  5e-13\n",
      "19: -3.0814e+02 -3.0814e+02  4e-04  1e-12  6e-13\n",
      "20: -3.0814e+02 -3.0814e+02  6e-06  2e-12  6e-13\n",
      "Optimal solution found.\n",
      "Model trained and saved to: models_rbf\\svm_rbf_model_C_0.01_gamma_0.0001.joblib\n",
      "Processing model with C = 0.01 and gamma = 0.001\n",
      "Training model with C = 0.01 and gamma = 0.001\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -9.7674e+03 -1.3599e+03  3e+05  3e+02  6e-12\n",
      " 1: -1.0566e+03 -9.0886e+02  2e+04  2e+01  6e-12\n",
      " 2: -2.4213e+02 -8.1492e+02  1e+03  7e-01  8e-13\n",
      " 3: -2.2215e+02 -3.6763e+02  1e+02  4e-13  2e-13\n",
      " 4: -2.4877e+02 -2.9058e+02  4e+01  5e-13  2e-13\n",
      " 5: -2.5438e+02 -2.8103e+02  3e+01  8e-14  2e-13\n",
      " 6: -2.6130e+02 -2.6892e+02  8e+00  1e-13  2e-13\n",
      " 7: -2.6296e+02 -2.6635e+02  3e+00  4e-13  2e-13\n",
      " 8: -2.6393e+02 -2.6503e+02  1e+00  1e-12  2e-13\n",
      " 9: -2.6416e+02 -2.6472e+02  6e-01  2e-13  2e-13\n",
      "10: -2.6436e+02 -2.6448e+02  1e-01  1e-14  2e-13\n",
      "11: -2.6440e+02 -2.6443e+02  2e-02  9e-14  2e-13\n",
      "12: -2.6441e+02 -2.6442e+02  4e-03  8e-13  2e-13\n",
      "13: -2.6442e+02 -2.6442e+02  1e-04  6e-13  3e-13\n",
      "Optimal solution found.\n",
      "Model trained and saved to: models_rbf\\svm_rbf_model_C_0.01_gamma_0.001.joblib\n",
      "Processing model with C = 0.01 and gamma = 0.01\n",
      "Training model with C = 0.01 and gamma = 0.01\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -6.3926e+03 -2.3136e+03  2e+05  3e+02  6e-14\n",
      " 1: -1.7799e+03 -9.6771e+02  2e+04  2e+01  6e-14\n",
      " 2: -3.4853e+02 -7.8345e+02  1e+03  1e+00  2e-14\n",
      " 3: -2.7141e+02 -4.5920e+02  2e+02  6e-13  1e-14\n",
      " 4: -3.0799e+02 -3.2651e+02  2e+01  2e-13  1e-14\n",
      " 5: -3.1304e+02 -3.2104e+02  8e+00  4e-13  1e-14\n",
      " 6: -3.1536e+02 -3.1851e+02  3e+00  2e-13  1e-14\n",
      " 7: -3.1669e+02 -3.1706e+02  4e-01  8e-13  1e-14\n",
      " 8: -3.1673e+02 -3.1702e+02  3e-01  4e-14  1e-14\n",
      " 9: -3.1679e+02 -3.1696e+02  2e-01  5e-13  1e-14\n",
      "10: -3.1685e+02 -3.1690e+02  4e-02  3e-13  1e-14\n",
      "11: -3.1687e+02 -3.1688e+02  7e-03  4e-13  1e-14\n",
      "12: -3.1687e+02 -3.1687e+02  1e-04  1e-12  1e-14\n",
      "Optimal solution found.\n",
      "Model trained and saved to: models_rbf\\svm_rbf_model_C_0.01_gamma_0.01.joblib\n",
      "Processing model with C = 0.01 and gamma = 0.1\n",
      "Training model with C = 0.01 and gamma = 0.1\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -9.2668e+03 -2.5214e+03  2e+05  2e+02  3e-15\n",
      " 1: -1.8731e+03 -7.5282e+02  1e+04  2e+01  3e-15\n",
      " 2: -2.7318e+02 -6.7539e+02  4e+02  3e-11  8e-15\n",
      " 3: -3.0923e+02 -3.5808e+02  5e+01  6e-13  2e-15\n",
      " 4: -3.3088e+02 -3.3161e+02  7e-01  2e-11  3e-15\n",
      " 5: -3.3124e+02 -3.3125e+02  7e-03  2e-13  1e-15\n",
      " 6: -3.3124e+02 -3.3124e+02  7e-05  1e-11  6e-16\n",
      "Optimal solution found.\n",
      "Model trained and saved to: models_rbf\\svm_rbf_model_C_0.01_gamma_0.1.joblib\n",
      "Processing model with C = 0.01 and gamma = 1\n",
      "Training model with C = 0.01 and gamma = 1\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -9.3148e+03 -2.4971e+03  1e+05  2e+02  2e-16\n",
      " 1: -1.6640e+03 -7.2085e+02  7e+03  1e+01  4e-16\n",
      " 2: -2.9278e+02 -6.4224e+02  3e+02  2e-10  5e-16\n",
      " 3: -3.1987e+02 -3.4049e+02  2e+01  5e-11  5e-16\n",
      " 4: -3.3115e+02 -3.3137e+02  2e-01  8e-11  2e-16\n",
      " 5: -3.3127e+02 -3.3127e+02  2e-03  4e-11  1e-16\n",
      " 6: -3.3127e+02 -3.3127e+02  2e-05  3e-11  1e-16\n",
      "Optimal solution found.\n",
      "Model trained and saved to: models_rbf\\svm_rbf_model_C_0.01_gamma_1.joblib\n",
      "Processing model with C = 0.01 and gamma = 10\n",
      "Training model with C = 0.01 and gamma = 10\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -9.3149e+03 -2.4971e+03  1e+05  2e+02  2e-16\n",
      " 1: -1.6640e+03 -7.2085e+02  7e+03  1e+01  3e-16\n",
      " 2: -2.9278e+02 -6.4224e+02  3e+02  9e-11  8e-16\n",
      " 3: -3.1987e+02 -3.4049e+02  2e+01  1e-11  4e-16\n",
      " 4: -3.3115e+02 -3.3137e+02  2e-01  3e-13  2e-16\n",
      " 5: -3.3127e+02 -3.3127e+02  2e-03  4e-11  3e-16\n",
      " 6: -3.3127e+02 -3.3127e+02  2e-05  5e-11  2e-16\n",
      "Optimal solution found.\n",
      "Model trained and saved to: models_rbf\\svm_rbf_model_C_0.01_gamma_10.joblib\n",
      "Processing model with C = 0.01 and gamma = 0.0001\n",
      "Model already exists for C = 0.01 and gamma = 0.0001. Skipping training.\n",
      "Processing model with C = 0.01 and gamma = 0.001\n",
      "Model already exists for C = 0.01 and gamma = 0.001. Skipping training.\n",
      "Processing model with C = 0.01 and gamma = 0.01\n",
      "Model already exists for C = 0.01 and gamma = 0.01. Skipping training.\n",
      "Processing model with C = 0.01 and gamma = 0.1\n",
      "Model already exists for C = 0.01 and gamma = 0.1. Skipping training.\n",
      "Processing model with C = 0.01 and gamma = 1\n",
      "Model already exists for C = 0.01 and gamma = 1. Skipping training.\n",
      "Processing model with C = 0.01 and gamma = 10\n",
      "Model already exists for C = 0.01 and gamma = 10. Skipping training.\n",
      "Processing model with C = 1 and gamma = 0.0001\n",
      "Training model with C = 1 and gamma = 0.0001\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.3277e+04 -1.0912e+05  6e+05  4e+00  3e-11\n",
      " 1: -1.5741e+04 -8.1585e+04  9e+04  3e-01  4e-11\n",
      " 2: -1.6977e+04 -2.6945e+04  1e+04  2e-02  3e-11\n",
      " 3: -1.9759e+04 -2.3306e+04  4e+03  6e-03  3e-11\n",
      " 4: -2.0543e+04 -2.2432e+04  2e+03  3e-03  3e-11\n",
      " 5: -2.0998e+04 -2.1896e+04  9e+02  1e-03  3e-11\n",
      " 6: -2.1208e+04 -2.1653e+04  5e+02  5e-04  3e-11\n",
      " 7: -2.1343e+04 -2.1496e+04  2e+02  1e-04  3e-11\n",
      " 8: -2.1394e+04 -2.1438e+04  4e+01  2e-05  4e-11\n",
      " 9: -2.1411e+04 -2.1419e+04  8e+00  9e-07  4e-11\n",
      "10: -2.1414e+04 -2.1415e+04  1e+00  1e-07  4e-11\n",
      "11: -2.1415e+04 -2.1415e+04  9e-02  7e-09  4e-11\n",
      "12: -2.1415e+04 -2.1415e+04  2e-03  2e-10  4e-11\n",
      "Optimal solution found.\n",
      "Model trained and saved to: models_rbf\\svm_rbf_model_C_1_gamma_0.0001.joblib\n",
      "Processing model with C = 1 and gamma = 0.001\n",
      "Training model with C = 1 and gamma = 0.001\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.8265e+04 -9.6373e+04  5e+05  3e+00  1e-11\n",
      " 1: -1.3299e+04 -6.9811e+04  9e+04  3e-01  2e-11\n",
      " 2: -1.3668e+04 -2.2162e+04  9e+03  6e-03  1e-11\n",
      " 3: -1.5254e+04 -1.9878e+04  5e+03  3e-03  1e-11\n",
      " 4: -1.5937e+04 -1.8892e+04  3e+03  2e-03  1e-11\n",
      " 5: -1.6399e+04 -1.8234e+04  2e+03  9e-04  1e-11\n",
      " 6: -1.6732e+04 -1.7757e+04  1e+03  4e-04  1e-11\n",
      " 7: -1.6926e+04 -1.7486e+04  6e+02  2e-04  1e-11\n",
      " 8: -1.7087e+04 -1.7259e+04  2e+02  4e-05  2e-11\n",
      " 9: -1.7145e+04 -1.7180e+04  4e+01  6e-11  2e-11\n",
      "10: -1.7159e+04 -1.7163e+04  4e+00  4e-11  2e-11\n",
      "11: -1.7161e+04 -1.7161e+04  2e-01  1e-11  2e-11\n",
      "12: -1.7161e+04 -1.7161e+04  8e-03  2e-11  2e-11\n",
      "Optimal solution found.\n",
      "Model trained and saved to: models_rbf\\svm_rbf_model_C_1_gamma_0.001.joblib\n",
      "Processing model with C = 1 and gamma = 0.01\n",
      "Training model with C = 1 and gamma = 0.01\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -9.5211e+03 -7.9108e+04  3e+05  2e+00  1e-13\n",
      " 1: -8.6533e+03 -5.4585e+04  7e+04  3e-01  2e-13\n",
      " 2: -9.0792e+03 -1.6837e+04  8e+03  2e-02  2e-13\n",
      " 3: -9.8137e+03 -1.1933e+04  2e+03  4e-03  2e-13\n",
      " 4: -1.0081e+04 -1.0628e+04  6e+02  7e-04  2e-13\n",
      " 5: -1.0159e+04 -1.0268e+04  1e+02  7e-05  2e-13\n",
      " 6: -1.0176e+04 -1.0192e+04  2e+01  4e-06  2e-13\n",
      " 7: -1.0179e+04 -1.0180e+04  9e-01  2e-07  2e-13\n",
      " 8: -1.0179e+04 -1.0179e+04  5e-02  9e-09  2e-13\n",
      " 9: -1.0179e+04 -1.0179e+04  2e-03  2e-10  2e-13\n",
      "Optimal solution found.\n",
      "Model trained and saved to: models_rbf\\svm_rbf_model_C_1_gamma_0.01.joblib\n",
      "Processing model with C = 1 and gamma = 0.1\n",
      "Training model with C = 1 and gamma = 0.1\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.4679e+04 -6.6914e+04  2e+05  2e+00  4e-15\n",
      " 1: -1.4212e+04 -3.9853e+04  3e+04  7e-11  2e-15\n",
      " 2: -1.5458e+04 -1.8140e+04  3e+03  3e-10  3e-15\n",
      " 3: -1.6308e+04 -1.6725e+04  4e+02  2e-10  2e-15\n",
      " 4: -1.6451e+04 -1.6512e+04  6e+01  2e-10  2e-15\n",
      " 5: -1.6474e+04 -1.6482e+04  8e+00  6e-10  1e-15\n",
      " 6: -1.6477e+04 -1.6478e+04  1e+00  1e-09  1e-15\n",
      " 7: -1.6477e+04 -1.6478e+04  1e-01  9e-10  1e-15\n",
      " 8: -1.6477e+04 -1.6478e+04  2e-02  8e-10  1e-15\n",
      " 9: -1.6477e+04 -1.6477e+04  2e-03  1e-10  1e-15\n",
      "Optimal solution found.\n",
      "Model trained and saved to: models_rbf\\svm_rbf_model_C_1_gamma_0.1.joblib\n",
      "Processing model with C = 1 and gamma = 1\n",
      "Training model with C = 1 and gamma = 1\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.4782e+04 -6.2879e+04  1e+05  1e+00  6e-16\n",
      " 1: -1.4408e+04 -3.6386e+04  2e+04  1e-09  2e-16\n",
      " 2: -1.5716e+04 -1.7717e+04  2e+03  2e-09  8e-17\n",
      " 3: -1.6492e+04 -1.6793e+04  3e+02  1e-10  6e-17\n",
      " 4: -1.6607e+04 -1.6648e+04  4e+01  7e-09  5e-17\n",
      " 5: -1.6624e+04 -1.6630e+04  6e+00  6e-09  4e-17\n",
      " 6: -1.6626e+04 -1.6627e+04  8e-01  4e-10  4e-17\n",
      " 7: -1.6627e+04 -1.6627e+04  1e-01  5e-09  3e-17\n",
      " 8: -1.6627e+04 -1.6627e+04  2e-02  3e-09  5e-17\n",
      " 9: -1.6627e+04 -1.6627e+04  2e-03  3e-09  4e-17\n",
      "Optimal solution found.\n",
      "Model trained and saved to: models_rbf\\svm_rbf_model_C_1_gamma_1.joblib\n",
      "Processing model with C = 1 and gamma = 10\n",
      "Training model with C = 1 and gamma = 10\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.4782e+04 -6.2879e+04  1e+05  1e+00  4e-16\n",
      " 1: -1.4408e+04 -3.6386e+04  2e+04  4e-09  2e-16\n",
      " 2: -1.5717e+04 -1.7717e+04  2e+03  2e-09  1e-16\n",
      " 3: -1.6493e+04 -1.6793e+04  3e+02  6e-09  6e-17\n",
      " 4: -1.6607e+04 -1.6649e+04  4e+01  3e-09  4e-17\n",
      " 5: -1.6624e+04 -1.6630e+04  6e+00  2e-09  5e-17\n",
      " 6: -1.6627e+04 -1.6627e+04  8e-01  1e-09  4e-17\n",
      " 7: -1.6627e+04 -1.6627e+04  1e-01  4e-09  4e-17\n",
      " 8: -1.6627e+04 -1.6627e+04  2e-02  1e-08  3e-17\n",
      " 9: -1.6627e+04 -1.6627e+04  2e-03  6e-09  4e-17\n",
      "Optimal solution found.\n",
      "Model trained and saved to: models_rbf\\svm_rbf_model_C_1_gamma_10.joblib\n",
      "Processing model with C = 5 and gamma = 0.0001\n",
      "Training model with C = 5 and gamma = 0.0001\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -6.2409e+04 -9.6351e+05  2e+06  1e+00  1e-10\n",
      " 1: -5.6948e+04 -3.9375e+05  3e+05  9e-11  1e-10\n",
      " 2: -7.1907e+04 -1.5124e+05  8e+04  7e-11  1e-10\n",
      " 3: -8.3000e+04 -1.2530e+05  4e+04  2e-10  1e-10\n",
      " 4: -8.9561e+04 -1.1043e+05  2e+04  1e-10  1e-10\n",
      " 5: -9.2433e+04 -1.0477e+05  1e+04  1e-10  1e-10\n",
      " 6: -9.4558e+04 -1.0077e+05  6e+03  4e-10  1e-10\n",
      " 7: -9.5714e+04 -9.8741e+04  3e+03  3e-10  2e-10\n",
      " 8: -9.6408e+04 -9.7582e+04  1e+03  3e-10  2e-10\n",
      " 9: -9.6700e+04 -9.7120e+04  4e+02  2e-10  2e-10\n",
      "10: -9.6842e+04 -9.6928e+04  9e+01  5e-10  2e-10\n",
      "11: -9.6876e+04 -9.6886e+04  1e+01  6e-10  2e-10\n",
      "12: -9.6880e+04 -9.6881e+04  8e-01  4e-11  2e-10\n",
      "13: -9.6881e+04 -9.6881e+04  5e-02  8e-11  2e-10\n",
      "Optimal solution found.\n",
      "Model trained and saved to: models_rbf\\svm_rbf_model_C_5_gamma_0.0001.joblib\n",
      "Processing model with C = 5 and gamma = 0.001\n",
      "Training model with C = 5 and gamma = 0.001\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.1747e+04 -9.1450e+05  2e+06  1e+00  4e-11\n",
      " 1: -3.7270e+04 -4.2243e+05  5e+05  1e-01  5e-11\n",
      " 2: -4.4961e+04 -1.3426e+05  9e+04  2e-02  5e-11\n",
      " 3: -5.0845e+04 -1.0892e+05  6e+04  1e-02  5e-11\n",
      " 4: -5.6709e+04 -8.1824e+04  3e+04  4e-03  5e-11\n",
      " 5: -5.9833e+04 -7.2276e+04  1e+04  1e-03  6e-11\n",
      " 6: -6.1945e+04 -6.6500e+04  5e+03  4e-04  6e-11\n",
      " 7: -6.2882e+04 -6.4276e+04  1e+03  6e-05  7e-11\n",
      " 8: -6.3182e+04 -6.3632e+04  5e+02  2e-11  7e-11\n",
      " 9: -6.3327e+04 -6.3402e+04  8e+01  1e-10  7e-11\n",
      "10: -6.3354e+04 -6.3360e+04  5e+00  1e-10  7e-11\n",
      "11: -6.3356e+04 -6.3356e+04  2e-01  6e-11  7e-11\n",
      "12: -6.3356e+04 -6.3356e+04  4e-03  3e-11  7e-11\n",
      "Optimal solution found.\n",
      "Model trained and saved to: models_rbf\\svm_rbf_model_C_5_gamma_0.001.joblib\n",
      "Processing model with C = 5 and gamma = 0.01\n",
      "Training model with C = 5 and gamma = 0.01\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  9.4674e+03 -7.3799e+05  2e+06  8e-01  4e-13\n",
      " 1:  1.0640e+04 -2.5441e+05  3e+05  3e-02  5e-13\n",
      " 2: -5.1661e+03 -7.0830e+04  7e+04  7e-03  4e-13\n",
      " 3: -1.0858e+04 -2.8217e+04  2e+04  9e-04  4e-13\n",
      " 4: -1.1943e+04 -1.6555e+04  5e+03  8e-05  3e-13\n",
      " 5: -1.2139e+04 -1.3199e+04  1e+03  1e-05  3e-13\n",
      " 6: -1.2188e+04 -1.2364e+04  2e+02  1e-06  3e-13\n",
      " 7: -1.2199e+04 -1.2221e+04  2e+01  1e-07  3e-13\n",
      " 8: -1.2201e+04 -1.2203e+04  2e+00  7e-09  3e-13\n",
      " 9: -1.2201e+04 -1.2201e+04  1e-01  4e-10  3e-13\n",
      "10: -1.2201e+04 -1.2201e+04  2e-03  9e-12  3e-13\n",
      "Optimal solution found.\n",
      "Model trained and saved to: models_rbf\\svm_rbf_model_C_5_gamma_0.01.joblib\n",
      "Processing model with C = 5 and gamma = 0.1\n",
      "Training model with C = 5 and gamma = 0.1\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.6051e+02 -4.8824e+05  5e+05  6e-10  2e-14\n",
      " 1: -1.0792e+04 -6.3618e+04  5e+04  8e-10  4e-15\n",
      " 2: -1.6311e+04 -2.1349e+04  5e+03  2e-10  3e-15\n",
      " 3: -1.6493e+04 -1.6940e+04  4e+02  5e-10  2e-15\n",
      " 4: -1.6495e+04 -1.6508e+04  1e+01  8e-11  1e-15\n",
      " 5: -1.6495e+04 -1.6495e+04  2e-01  4e-10  1e-15\n",
      " 6: -1.6495e+04 -1.6495e+04  3e-03  7e-10  7e-16\n",
      "Optimal solution found.\n",
      "Model trained and saved to: models_rbf\\svm_rbf_model_C_5_gamma_0.1.joblib\n",
      "Processing model with C = 5 and gamma = 1\n",
      "Training model with C = 5 and gamma = 1\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  5.7740e+01 -3.1614e+05  3e+05  7e-09  1e-15\n",
      " 1: -1.2554e+04 -5.5195e+04  4e+04  6e-09  5e-16\n",
      " 2: -1.6546e+04 -1.9619e+04  3e+03  6e-09  2e-16\n",
      " 3: -1.6635e+04 -1.6686e+04  5e+01  6e-09  8e-17\n",
      " 4: -1.6635e+04 -1.6635e+04  5e-01  7e-09  5e-17\n",
      " 5: -1.6635e+04 -1.6635e+04  5e-03  6e-09  4e-17\n",
      "Optimal solution found.\n",
      "Model trained and saved to: models_rbf\\svm_rbf_model_C_5_gamma_1.joblib\n",
      "Processing model with C = 5 and gamma = 10\n",
      "Training model with C = 5 and gamma = 10\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  5.7003e+01 -3.1614e+05  3e+05  1e-08  8e-16\n",
      " 1: -1.2555e+04 -5.5195e+04  4e+04  1e-08  5e-16\n",
      " 2: -1.6546e+04 -1.9620e+04  3e+03  1e-10  1e-16\n",
      " 3: -1.6635e+04 -1.6686e+04  5e+01  3e-10  1e-16\n",
      " 4: -1.6635e+04 -1.6636e+04  5e-01  8e-10  4e-17\n",
      " 5: -1.6635e+04 -1.6635e+04  5e-03  5e-09  6e-17\n",
      "Optimal solution found.\n",
      "Model trained and saved to: models_rbf\\svm_rbf_model_C_5_gamma_10.joblib\n",
      "Processing model with C = 10 and gamma = 0.0001\n",
      "Training model with C = 10 and gamma = 0.0001\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -9.7406e+04 -3.1685e+06  7e+06  8e-01  2e-10\n",
      " 1: -9.0186e+04 -1.0316e+06  9e+05  4e-10  2e-10\n",
      " 2: -1.2607e+05 -3.4391e+05  2e+05  1e-10  2e-10\n",
      " 3: -1.4726e+05 -2.7972e+05  1e+05  2e-10  2e-10\n",
      " 4: -1.6423e+05 -2.3079e+05  7e+04  1e-10  2e-10\n",
      " 5: -1.7177e+05 -2.1353e+05  4e+04  3e-10  2e-10\n",
      " 6: -1.7767e+05 -2.0077e+05  2e+04  5e-11  3e-10\n",
      " 7: -1.8119e+05 -1.9369e+05  1e+04  2e-10  3e-10\n",
      " 8: -1.8354e+05 -1.8930e+05  6e+03  3e-11  3e-10\n",
      " 9: -1.8486e+05 -1.8695e+05  2e+03  8e-11  3e-10\n",
      "10: -1.8546e+05 -1.8606e+05  6e+02  7e-10  3e-10\n",
      "11: -1.8566e+05 -1.8579e+05  1e+02  2e-10  3e-10\n",
      "12: -1.8571e+05 -1.8573e+05  2e+01  1e-10  3e-10\n",
      "13: -1.8572e+05 -1.8572e+05  2e+00  9e-11  3e-10\n",
      "14: -1.8572e+05 -1.8572e+05  7e-02  4e-10  3e-10\n",
      "Optimal solution found.\n",
      "Model trained and saved to: models_rbf\\svm_rbf_model_C_10_gamma_0.0001.joblib\n",
      "Processing model with C = 10 and gamma = 0.001\n",
      "Training model with C = 10 and gamma = 0.001\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.6634e+04 -3.0697e+06  7e+06  8e-01  8e-11\n",
      " 1: -3.7382e+04 -1.2088e+06  1e+06  7e-02  1e-10\n",
      " 2: -6.2263e+04 -3.3448e+05  3e+05  1e-02  9e-11\n",
      " 3: -7.4600e+04 -2.4545e+05  2e+05  7e-03  9e-11\n",
      " 4: -8.5954e+04 -1.6277e+05  8e+04  3e-03  1e-10\n",
      " 5: -9.3757e+04 -1.2745e+05  3e+04  9e-04  1e-10\n",
      " 6: -9.8346e+04 -1.1123e+05  1e+04  2e-04  1e-10\n",
      " 7: -1.0048e+05 -1.0478e+05  4e+03  3e-05  1e-10\n",
      " 8: -1.0137e+05 -1.0246e+05  1e+03  2e-06  1e-10\n",
      " 9: -1.0166e+05 -1.0185e+05  2e+02  2e-07  1e-10\n",
      "10: -1.0172e+05 -1.0174e+05  2e+01  1e-08  1e-10\n",
      "11: -1.0173e+05 -1.0173e+05  7e-01  4e-10  1e-10\n",
      "12: -1.0173e+05 -1.0173e+05  2e-02  1e-10  1e-10\n",
      "Optimal solution found.\n",
      "Model trained and saved to: models_rbf\\svm_rbf_model_C_10_gamma_0.001.joblib\n",
      "Processing model with C = 10 and gamma = 0.01\n",
      "Training model with C = 10 and gamma = 0.01\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.0451e+05 -2.4111e+06  5e+06  6e-01  7e-13\n",
      " 1:  9.0542e+04 -6.2186e+05  7e+05  2e-02  9e-13\n",
      " 2:  1.7543e+04 -1.6898e+05  2e+05  3e-03  7e-13\n",
      " 3: -4.6111e+03 -7.1480e+04  7e+04  8e-04  5e-13\n",
      " 4: -1.1284e+04 -2.8306e+04  2e+04  7e-05  4e-13\n",
      " 5: -1.2410e+04 -1.5782e+04  3e+03  4e-06  3e-13\n",
      " 6: -1.2558e+04 -1.3409e+04  9e+02  9e-07  3e-13\n",
      " 7: -1.2600e+04 -1.2734e+04  1e+02  6e-08  3e-13\n",
      " 8: -1.2609e+04 -1.2625e+04  2e+01  5e-09  3e-13\n",
      " 9: -1.2610e+04 -1.2611e+04  1e+00  3e-10  3e-13\n",
      "10: -1.2610e+04 -1.2610e+04  6e-02  5e-11  3e-13\n",
      "11: -1.2610e+04 -1.2610e+04  1e-03  4e-11  3e-13\n",
      "Optimal solution found.\n",
      "Model trained and saved to: models_rbf\\svm_rbf_model_C_10_gamma_0.01.joblib\n",
      "Processing model with C = 10 and gamma = 0.1\n",
      "Training model with C = 10 and gamma = 0.1\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.0282e+05 -1.4924e+06  2e+06  1e-09  4e-14\n",
      " 1:  2.2984e+04 -1.8631e+05  2e+05  1e-09  1e-14\n",
      " 2: -1.3285e+04 -4.0838e+04  3e+04  2e-10  6e-15\n",
      " 3: -1.6464e+04 -1.8320e+04  2e+03  1e-10  3e-15\n",
      " 4: -1.6505e+04 -1.6613e+04  1e+02  4e-10  2e-15\n",
      " 5: -1.6505e+04 -1.6508e+04  3e+00  7e-10  1e-15\n",
      " 6: -1.6505e+04 -1.6505e+04  5e-02  6e-10  9e-16\n",
      " 7: -1.6505e+04 -1.6505e+04  6e-04  5e-11  6e-16\n",
      "Optimal solution found.\n",
      "Model trained and saved to: models_rbf\\svm_rbf_model_C_10_gamma_0.1.joblib\n",
      "Processing model with C = 10 and gamma = 1\n",
      "Training model with C = 10 and gamma = 1\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.0186e+05 -8.6137e+05  1e+06  5e-09  2e-15\n",
      " 1:  1.0522e+04 -1.2609e+05  1e+05  5e-09  4e-16\n",
      " 2: -1.4939e+04 -3.3662e+04  2e+04  4e-09  1e-16\n",
      " 3: -1.6634e+04 -1.7563e+04  9e+02  3e-09  1e-16\n",
      " 4: -1.6645e+04 -1.6655e+04  1e+01  6e-09  1e-16\n",
      " 5: -1.6645e+04 -1.6645e+04  1e-01  4e-10  8e-17\n",
      " 6: -1.6645e+04 -1.6645e+04  1e-03  3e-09  3e-17\n",
      "Optimal solution found.\n",
      "Model trained and saved to: models_rbf\\svm_rbf_model_C_10_gamma_1.joblib\n",
      "Processing model with C = 10 and gamma = 10\n",
      "Training model with C = 10 and gamma = 10\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.0186e+05 -8.6138e+05  1e+06  1e-09  2e-15\n",
      " 1:  1.0525e+04 -1.2607e+05  1e+05  7e-09  7e-16\n",
      " 2: -1.4939e+04 -3.3664e+04  2e+04  8e-09  3e-16\n",
      " 3: -1.6634e+04 -1.7563e+04  9e+02  1e-09  8e-17\n",
      " 4: -1.6645e+04 -1.6655e+04  1e+01  2e-09  5e-17\n",
      " 5: -1.6645e+04 -1.6645e+04  1e-01  3e-09  4e-17\n",
      " 6: -1.6645e+04 -1.6645e+04  1e-03  1e-09  4e-17\n",
      "Optimal solution found.\n",
      "Model trained and saved to: models_rbf\\svm_rbf_model_C_10_gamma_10.joblib\n",
      "All models processed.\n"
     ]
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "import gc\n",
    "\n",
    "# Test with multiple values of C\n",
    "C_values = [0.001, 0.01, 0.01, 1, 5, 10]\n",
    "# Test with multiple values of C and gamma\n",
    "gamma_values = [0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
    "\n",
    "# Ensure the models directory exists\n",
    "os.makedirs('models_rbf', exist_ok=True)\n",
    "\n",
    "for C in C_values:\n",
    "    for gamma in gamma_values:\n",
    "        print(f\"Processing model with C = {C} and gamma = {gamma}\")\n",
    "        \n",
    "        # Define the model file path\n",
    "        model_path = os.path.join('models_rbf', f'svm_rbf_model_C_{C}_gamma_{gamma}.joblib')\n",
    "\n",
    "        # Check if the model already exists\n",
    "        if os.path.exists(model_path):\n",
    "            print(f\"Model already exists for C = {C} and gamma = {gamma}. Skipping training.\")\n",
    "        else:\n",
    "            print(f\"Training model with C = {C} and gamma = {gamma}\")\n",
    "            model = SVM_RBF(C=C, gamma=gamma)\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # Save the model\n",
    "            dump(model, model_path, compress=3)\n",
    "            print(f\"Model trained and saved to: {model_path}\")\n",
    "\n",
    "            # Clear the model from memory\n",
    "            del model\n",
    "            gc.collect()  # Force garbage collection\n",
    "\n",
    "print(\"All models processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing models:\n",
      "\n",
      "Testing model with C = 0.001 and gamma = 0.0001\n",
      "X_test.shape: (5067, 1280)\n",
      "y_test.shape: (5067,)\n",
      "Projected: [-0.05175196  0.01005338 -0.03997785 -0.09219643 -0.04808763]\n",
      "Predicted: [-1.  1. -1. -1. -1.]\n",
      "Confusion Matrix:\n",
      " [[2840 1322]\n",
      " [ 402  503]]\n",
      "Recall for C = 0.001, gamma = 0.0001: 0.5558\n",
      "\n",
      "Testing model with C = 0.001 and gamma = 0.001\n",
      "X_test.shape: (5067, 1280)\n",
      "y_test.shape: (5067,)\n",
      "Projected: [-0.20900759  0.05459904 -0.17112098 -0.50270861 -0.21472663]\n",
      "Predicted: [-1.  1. -1. -1. -1.]\n",
      "Confusion Matrix:\n",
      " [[2791 1371]\n",
      " [ 367  538]]\n",
      "Recall for C = 0.001, gamma = 0.001: 0.5945\n",
      "\n",
      "Testing model with C = 0.001 and gamma = 0.01\n",
      "X_test.shape: (5067, 1280)\n",
      "y_test.shape: (5067,)\n",
      "Projected: [-0.00316552  0.00018406 -0.00178422 -0.05845731 -0.00237685]\n",
      "Predicted: [-1.  1. -1. -1. -1.]\n",
      "Confusion Matrix:\n",
      " [[2810 1352]\n",
      " [ 273  632]]\n",
      "Recall for C = 0.001, gamma = 0.01: 0.6983\n",
      "\n",
      "Testing model with C = 0.001 and gamma = 0.1\n",
      "X_test.shape: (5067, 1280)\n",
      "y_test.shape: (5067,)\n",
      "Projected: [7.18639032e-06 7.21719914e-06 2.09021171e-06 7.21717527e-06\n",
      " 7.21720297e-06]\n",
      "Predicted: [1. 1. 1. 1. 1.]\n",
      "Confusion Matrix:\n",
      " [[ 338 3824]\n",
      " [  17  888]]\n",
      "Recall for C = 0.001, gamma = 0.1: 0.9812\n",
      "\n",
      "Testing model with C = 0.001 and gamma = 1\n",
      "X_test.shape: (5067, 1280)\n",
      "y_test.shape: (5067,)\n",
      "Projected: [4.71060075e-07 4.71060075e-07 4.71060075e-07 4.71060075e-07\n",
      " 4.71060075e-07]\n",
      "Predicted: [1. 1. 1. 1. 1.]\n",
      "Confusion Matrix:\n",
      " [[  14 4148]\n",
      " [   0  905]]\n",
      "Recall for C = 0.001, gamma = 1: 1.0000\n",
      "\n",
      "Testing model with C = 0.001 and gamma = 10\n",
      "X_test.shape: (5067, 1280)\n",
      "y_test.shape: (5067,)\n",
      "Projected: [4.8056695e-07 4.8056695e-07 4.8056695e-07 4.8056695e-07 4.8056695e-07]\n",
      "Predicted: [1. 1. 1. 1. 1.]\n",
      "Confusion Matrix:\n",
      " [[  13 4149]\n",
      " [   0  905]]\n",
      "Recall for C = 0.001, gamma = 10: 1.0000\n",
      "\n",
      "Testing model with C = 0.01 and gamma = 0.0001\n",
      "X_test.shape: (5067, 1280)\n",
      "y_test.shape: (5067,)\n",
      "Projected: [-0.44511396  0.09981999 -0.35390201 -0.82855514 -0.45906654]\n",
      "Predicted: [-1.  1. -1. -1. -1.]\n",
      "Confusion Matrix:\n",
      " [[2838 1324]\n",
      " [ 390  515]]\n",
      "Recall for C = 0.01, gamma = 0.0001: 0.5691\n",
      "\n",
      "Testing model with C = 0.01 and gamma = 0.001\n",
      "X_test.shape: (5067, 1280)\n",
      "y_test.shape: (5067,)\n",
      "Projected: [-0.37611307 -0.05149912 -0.1700625  -1.46043525 -0.94827697]\n",
      "Predicted: [-1. -1. -1. -1. -1.]\n",
      "Confusion Matrix:\n",
      " [[2957 1205]\n",
      " [ 298  607]]\n",
      "Recall for C = 0.01, gamma = 0.001: 0.6707\n",
      "\n",
      "Testing model with C = 0.01 and gamma = 0.01\n",
      "X_test.shape: (5067, 1280)\n",
      "y_test.shape: (5067,)\n",
      "Projected: [-0.03141386  0.00208822 -0.01768105 -0.58276344 -0.02348133]\n",
      "Predicted: [-1.  1. -1. -1. -1.]\n",
      "Confusion Matrix:\n",
      " [[2806 1356]\n",
      " [ 271  634]]\n",
      "Recall for C = 0.01, gamma = 0.01: 0.7006\n",
      "\n",
      "Testing model with C = 0.01 and gamma = 0.1\n",
      "X_test.shape: (5067, 1280)\n",
      "y_test.shape: (5067,)\n",
      "Projected: [7.18638981e-05 7.21719863e-05 2.09021154e-05 7.21717476e-05\n",
      " 7.21720246e-05]\n",
      "Predicted: [1. 1. 1. 1. 1.]\n",
      "Confusion Matrix:\n",
      " [[ 338 3824]\n",
      " [  17  888]]\n",
      "Recall for C = 0.01, gamma = 0.1: 0.9812\n",
      "\n",
      "Testing model with C = 0.01 and gamma = 1\n",
      "X_test.shape: (5067, 1280)\n",
      "y_test.shape: (5067,)\n",
      "Projected: [4.71060183e-06 4.71060183e-06 4.71060183e-06 4.71060183e-06\n",
      " 4.71060183e-06]\n",
      "Predicted: [1. 1. 1. 1. 1.]\n",
      "Confusion Matrix:\n",
      " [[  14 4148]\n",
      " [   0  905]]\n",
      "Recall for C = 0.01, gamma = 1: 1.0000\n",
      "\n",
      "Testing model with C = 0.01 and gamma = 10\n",
      "X_test.shape: (5067, 1280)\n",
      "y_test.shape: (5067,)\n",
      "Projected: [4.8056706e-06 4.8056706e-06 4.8056706e-06 4.8056706e-06 4.8056706e-06]\n",
      "Predicted: [1. 1. 1. 1. 1.]\n",
      "Confusion Matrix:\n",
      " [[  13 4149]\n",
      " [   0  905]]\n",
      "Recall for C = 0.01, gamma = 10: 1.0000\n",
      "\n",
      "Testing model with C = 0.01 and gamma = 0.0001\n",
      "X_test.shape: (5067, 1280)\n",
      "y_test.shape: (5067,)\n",
      "Projected: [-0.44511396  0.09981999 -0.35390201 -0.82855514 -0.45906654]\n",
      "Predicted: [-1.  1. -1. -1. -1.]\n",
      "Confusion Matrix:\n",
      " [[2838 1324]\n",
      " [ 390  515]]\n",
      "Recall for C = 0.01, gamma = 0.0001: 0.5691\n",
      "\n",
      "Testing model with C = 0.01 and gamma = 0.001\n",
      "X_test.shape: (5067, 1280)\n",
      "y_test.shape: (5067,)\n",
      "Projected: [-0.37611307 -0.05149912 -0.1700625  -1.46043525 -0.94827697]\n",
      "Predicted: [-1. -1. -1. -1. -1.]\n",
      "Confusion Matrix:\n",
      " [[2957 1205]\n",
      " [ 298  607]]\n",
      "Recall for C = 0.01, gamma = 0.001: 0.6707\n",
      "\n",
      "Testing model with C = 0.01 and gamma = 0.01\n",
      "X_test.shape: (5067, 1280)\n",
      "y_test.shape: (5067,)\n",
      "Projected: [-0.03141386  0.00208822 -0.01768105 -0.58276344 -0.02348133]\n",
      "Predicted: [-1.  1. -1. -1. -1.]\n",
      "Confusion Matrix:\n",
      " [[2806 1356]\n",
      " [ 271  634]]\n",
      "Recall for C = 0.01, gamma = 0.01: 0.7006\n",
      "\n",
      "Testing model with C = 0.01 and gamma = 0.1\n",
      "X_test.shape: (5067, 1280)\n",
      "y_test.shape: (5067,)\n",
      "Projected: [7.18638981e-05 7.21719863e-05 2.09021154e-05 7.21717476e-05\n",
      " 7.21720246e-05]\n",
      "Predicted: [1. 1. 1. 1. 1.]\n",
      "Confusion Matrix:\n",
      " [[ 338 3824]\n",
      " [  17  888]]\n",
      "Recall for C = 0.01, gamma = 0.1: 0.9812\n",
      "\n",
      "Testing model with C = 0.01 and gamma = 1\n",
      "X_test.shape: (5067, 1280)\n",
      "y_test.shape: (5067,)\n",
      "Projected: [4.71060183e-06 4.71060183e-06 4.71060183e-06 4.71060183e-06\n",
      " 4.71060183e-06]\n",
      "Predicted: [1. 1. 1. 1. 1.]\n",
      "Confusion Matrix:\n",
      " [[  14 4148]\n",
      " [   0  905]]\n",
      "Recall for C = 0.01, gamma = 1: 1.0000\n",
      "\n",
      "Testing model with C = 0.01 and gamma = 10\n",
      "X_test.shape: (5067, 1280)\n",
      "y_test.shape: (5067,)\n",
      "Projected: [4.8056706e-06 4.8056706e-06 4.8056706e-06 4.8056706e-06 4.8056706e-06]\n",
      "Predicted: [1. 1. 1. 1. 1.]\n",
      "Confusion Matrix:\n",
      " [[  13 4149]\n",
      " [   0  905]]\n",
      "Recall for C = 0.01, gamma = 10: 1.0000\n",
      "\n",
      "Testing model with C = 1 and gamma = 0.0001\n",
      "X_test.shape: (5067, 1280)\n",
      "y_test.shape: (5067,)\n",
      "Projected: [-0.56245118 -0.45453591 -0.16005702 -1.92401278 -1.05811177]\n",
      "Predicted: [-1. -1. -1. -1. -1.]\n",
      "Confusion Matrix:\n",
      " [[3097 1065]\n",
      " [ 259  646]]\n",
      "Recall for C = 1, gamma = 0.0001: 0.7138\n",
      "\n",
      "Testing model with C = 1 and gamma = 0.001\n",
      "X_test.shape: (5067, 1280)\n",
      "y_test.shape: (5067,)\n",
      "Projected: [-0.74054395 -0.5892173  -0.54092967 -2.1563156  -1.41066053]\n",
      "Predicted: [-1. -1. -1. -1. -1.]\n",
      "Confusion Matrix:\n",
      " [[3312  850]\n",
      " [ 253  652]]\n",
      "Recall for C = 1, gamma = 0.001: 0.7204\n",
      "\n",
      "Testing model with C = 1 and gamma = 0.01\n",
      "X_test.shape: (5067, 1280)\n",
      "y_test.shape: (5067,)\n",
      "Projected: [-0.47240047 -0.65451001 -0.77728351 -1.28980764 -0.39822019]\n",
      "Predicted: [-1. -1. -1. -1. -1.]\n",
      "Confusion Matrix:\n",
      " [[3658  504]\n",
      " [ 273  632]]\n",
      "Recall for C = 1, gamma = 0.01: 0.6983\n",
      "\n",
      "Testing model with C = 1 and gamma = 0.1\n",
      "X_test.shape: (5067, 1280)\n",
      "y_test.shape: (5067,)\n",
      "Projected: [ 0.0009166   0.00094741 -0.00417912  0.00094738  0.00094741]\n",
      "Predicted: [ 1.  1. -1.  1.  1.]\n",
      "Confusion Matrix:\n",
      " [[ 533 3629]\n",
      " [  21  884]]\n",
      "Recall for C = 1, gamma = 0.1: 0.9768\n",
      "\n",
      "Testing model with C = 1 and gamma = 1\n",
      "X_test.shape: (5067, 1280)\n",
      "y_test.shape: (5067,)\n",
      "Projected: [0.00023263 0.00023263 0.00023263 0.00023263 0.00023263]\n",
      "Predicted: [1. 1. 1. 1. 1.]\n",
      "Confusion Matrix:\n",
      " [[  15 4147]\n",
      " [   0  905]]\n",
      "Recall for C = 1, gamma = 1: 1.0000\n",
      "\n",
      "Testing model with C = 1 and gamma = 10\n",
      "X_test.shape: (5067, 1280)\n",
      "y_test.shape: (5067,)\n",
      "Projected: [0.00024089 0.00024089 0.00024089 0.00024089 0.00024089]\n",
      "Predicted: [1. 1. 1. 1. 1.]\n",
      "Confusion Matrix:\n",
      " [[  13 4149]\n",
      " [   0  905]]\n",
      "Recall for C = 1, gamma = 10: 1.0000\n",
      "\n",
      "Testing model with C = 5 and gamma = 0.0001\n",
      "X_test.shape: (5067, 1280)\n",
      "y_test.shape: (5067,)\n",
      "Projected: [-0.68858369 -0.47095669 -0.38696893 -2.04955031 -1.36684822]\n",
      "Predicted: [-1. -1. -1. -1. -1.]\n",
      "Confusion Matrix:\n",
      " [[3177  985]\n",
      " [ 253  652]]\n",
      "Recall for C = 5, gamma = 0.0001: 0.7204\n",
      "\n",
      "Testing model with C = 5 and gamma = 0.001\n",
      "X_test.shape: (5067, 1280)\n",
      "y_test.shape: (5067,)\n",
      "Projected: [-0.75774546 -0.44546079 -1.13369577 -2.30673941 -1.55853736]\n",
      "Predicted: [-1. -1. -1. -1. -1.]\n",
      "Confusion Matrix:\n",
      " [[3422  740]\n",
      " [ 255  650]]\n",
      "Recall for C = 5, gamma = 0.001: 0.7182\n",
      "\n",
      "Testing model with C = 5 and gamma = 0.01\n",
      "X_test.shape: (5067, 1280)\n",
      "y_test.shape: (5067,)\n",
      "Projected: [-0.49588206 -0.62853619 -0.83273121 -1.27812884 -0.39070201]\n",
      "Predicted: [-1. -1. -1. -1. -1.]\n",
      "Confusion Matrix:\n",
      " [[3717  445]\n",
      " [ 282  623]]\n",
      "Recall for C = 5, gamma = 0.01: 0.6884\n",
      "\n",
      "Testing model with C = 5 and gamma = 0.1\n",
      "X_test.shape: (5067, 1280)\n",
      "y_test.shape: (5067,)\n",
      "Projected: [ 0.00058907  0.0006199  -0.00451025  0.00061988  0.0006199 ]\n",
      "Predicted: [ 1.  1. -1.  1.  1.]\n",
      "Confusion Matrix:\n",
      " [[ 578 3584]\n",
      " [  22  883]]\n",
      "Recall for C = 5, gamma = 0.1: 0.9757\n",
      "\n",
      "Testing model with C = 5 and gamma = 1\n",
      "X_test.shape: (5067, 1280)\n",
      "y_test.shape: (5067,)\n",
      "Projected: [0.00023234 0.00023234 0.00023234 0.00023234 0.00023234]\n",
      "Predicted: [1. 1. 1. 1. 1.]\n",
      "Confusion Matrix:\n",
      " [[  15 4147]\n",
      " [   0  905]]\n",
      "Recall for C = 5, gamma = 1: 1.0000\n",
      "\n",
      "Testing model with C = 5 and gamma = 10\n",
      "X_test.shape: (5067, 1280)\n",
      "y_test.shape: (5067,)\n",
      "Projected: [0.00024059 0.00024059 0.00024059 0.00024059 0.00024059]\n",
      "Predicted: [1. 1. 1. 1. 1.]\n",
      "Confusion Matrix:\n",
      " [[  13 4149]\n",
      " [   0  905]]\n",
      "Recall for C = 5, gamma = 10: 1.0000\n",
      "\n",
      "Testing model with C = 10 and gamma = 0.0001\n",
      "X_test.shape: (5067, 1280)\n",
      "y_test.shape: (5067,)\n",
      "Projected: [-0.72699946 -0.42071872 -0.45686252 -2.11330733 -1.64624007]\n",
      "Predicted: [-1. -1. -1. -1. -1.]\n",
      "Confusion Matrix:\n",
      " [[3205  957]\n",
      " [ 253  652]]\n",
      "Recall for C = 10, gamma = 0.0001: 0.7204\n",
      "\n",
      "Testing model with C = 10 and gamma = 0.001\n",
      "X_test.shape: (5067, 1280)\n",
      "y_test.shape: (5067,)\n",
      "Projected: [-0.64964464 -0.64360093 -1.32436699 -2.14600945 -1.53509994]\n",
      "Predicted: [-1. -1. -1. -1. -1.]\n",
      "Confusion Matrix:\n",
      " [[3477  685]\n",
      " [ 246  659]]\n",
      "Recall for C = 10, gamma = 0.001: 0.7282\n",
      "\n",
      "Testing model with C = 10 and gamma = 0.01\n",
      "X_test.shape: (5067, 1280)\n",
      "y_test.shape: (5067,)\n",
      "Projected: [-0.49705627 -0.62952634 -0.83371664 -1.27911622 -0.39205981]\n",
      "Predicted: [-1. -1. -1. -1. -1.]\n",
      "Confusion Matrix:\n",
      " [[3717  445]\n",
      " [ 279  626]]\n",
      "Recall for C = 10, gamma = 0.01: 0.6917\n",
      "\n",
      "Testing model with C = 10 and gamma = 0.1\n",
      "X_test.shape: (5067, 1280)\n",
      "y_test.shape: (5067,)\n",
      "Projected: [ 0.0005853   0.00061613 -0.00451402  0.0006161   0.00061613]\n",
      "Predicted: [ 1.  1. -1.  1.  1.]\n",
      "Confusion Matrix:\n",
      " [[ 578 3584]\n",
      " [  22  883]]\n",
      "Recall for C = 10, gamma = 0.1: 0.9757\n",
      "\n",
      "Testing model with C = 10 and gamma = 1\n",
      "X_test.shape: (5067, 1280)\n",
      "y_test.shape: (5067,)\n",
      "Projected: [0.00023234 0.00023234 0.00023234 0.00023234 0.00023234]\n",
      "Predicted: [1. 1. 1. 1. 1.]\n",
      "Confusion Matrix:\n",
      " [[  15 4147]\n",
      " [   0  905]]\n",
      "Recall for C = 10, gamma = 1: 1.0000\n",
      "\n",
      "Testing model with C = 10 and gamma = 10\n",
      "X_test.shape: (5067, 1280)\n",
      "y_test.shape: (5067,)\n",
      "Projected: [0.00024059 0.00024059 0.00024059 0.00024059 0.00024059]\n",
      "Predicted: [1. 1. 1. 1. 1.]\n",
      "Confusion Matrix:\n",
      " [[  13 4149]\n",
      " [   0  905]]\n",
      "Recall for C = 10, gamma = 10: 1.0000\n",
      "\n",
      "Testing completed.\n"
     ]
    }
   ],
   "source": [
    "# Testing phase\n",
    "print(\"\\nTesting models:\")\n",
    "for C in C_values:\n",
    "    for gamma in gamma_values:\n",
    "        print(f\"\\nTesting model with C = {C} and gamma = {gamma}\")\n",
    "        \n",
    "        model_path = os.path.join('models_rbf', f'svm_rbf_model_C_{C}_gamma_{gamma}.joblib')\n",
    "        \n",
    "        # Load the model\n",
    "        model = load(model_path)  # This assumes the custom SVM_RBF class can be loaded properly\n",
    "        \n",
    "        # Perform predictions on the test set\n",
    "        print('X_test.shape:', X_test.shape)\n",
    "        print('y_test.shape:', y_test.shape)\n",
    "        \n",
    "        # Calculate raw decision function values (if equivalent to 'project')\n",
    "        y_proj = np.zeros(X_test.shape[0])\n",
    "        for i in range(0, X_test.shape[0], model.chunk_size):\n",
    "            end = min(i + model.chunk_size, X_test.shape[0])\n",
    "            K = model._rbf_kernel_numba(X_test[i:end], model.sv, model.gamma)\n",
    "            y_proj[i:end] = np.dot(K, model.a * model.sv_y) + model.b\n",
    "        \n",
    "        # Predicted labels\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Display first few results\n",
    "        print('Projected:', y_proj[:5])\n",
    "        print('Predicted:', y_pred[:5])\n",
    "        \n",
    "        # Confusion matrix and recall\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        \n",
    "        print('Confusion Matrix:\\n', cm)\n",
    "        print(f'Recall for C = {C}, gamma = {gamma}: {recall:.4f}')\n",
    "        \n",
    "        # Clear the model from memory\n",
    "        del model\n",
    "        gc.collect()\n",
    "\n",
    "print(\"\\nTesting completed.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5573269,
     "sourceId": 9216526,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "TA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
